```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)
```

```{r packages, include = FALSE}
library(tidyverse)
library(ggplot2)
library(ggmap)
library(factoextra)
library(ggfortify)
library(knitr)
library(kableExtra)
library(patchwork)
library(ggrepel)
library(fs)
library(Momocs)
```


```{r}
my_theme <-
  theme(panel.grid = element_blank(),
        panel.background = element_blank(),
        strip.background = element_blank(),
        axis.line = element_blank())
```

```{r data, echo=FALSE, message=FALSE}
neo_axes <- read_csv("data/micropasts-neoaxes1.csv", 
                     col_types = cols(.default = col_character()))

neo_axes_long <- neo_axes %>%
  pivot_longer(areablad:weight, 
               names_to = "feature",
               values_to = "measurement") %>%
  filter(!is.na(measurement)) %>%
  mutate(across("measurement", as.numeric))

feature_n <- neo_axes_long %>%
  group_by(feature, condition) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  group_by(condition) %>%
  mutate(n_scaled = n / max(n)) %>%
  arrange(desc(n))

most_common_features <- feature_n %>%
  filter(n > 385)

neo_axes_long_mcf <- neo_axes_long %>%
  semi_join(most_common_features, by = "feature") %>%
  filter(condition %in% c("complete", "cast", "roughout"))
```
# Results

## Data collection outcomes

### Image processing of axe drawings

The cropping was mostly successful, and often produced three images: plan, profile and top. Exceptions appear to occur for some where the original drawings had been labeled, as bounding boxes were drawn around writing, identifying it as shapes, so sometimes writing was also cropped, or cropped instead of one or more of the views. Another exception occurs when views are drawn too close together or are overlapping, as these are then all included in the same cropped image. Finally some of the profile views were cropped in half as many of these have the edge drawn through the centre, which tends to be bolder than the outline. Another point of concern is that the crops do not leave much room around the outlines, which sometimes led to problems later with the filling.

The filling method was overall successful, and the shape of many axes was retained, but some data was lost on the outlines, causing them to become jagged. Despite mostly succeeding in cropping three views from each drawing, I decided to only focus on the plans as that is where most of the variation seems to occur between each axe. Only the plans which had two other associated images were chosen, as if there were less or more than three, the wrong view may have ‘plan’ in the filename and would be included in error. Of the 1825 axe drawings, this brought the number to import into Momocs down to 1198.

### Crowdsourcing with MicroPasts

All 1825 record sheets were transcribed, so the project is now listed as complete on MicroPasts, and the raw data is publicly available. This data collection method took by far the longest as volunteer uptake was slow, and individual tasks took a while to fill out, with 66 fields to complete. Mostly authenticated users took part in the project, however interestingly, some anonymous users also contributed a number of transcriptions. Investigation of the recovered data showed almost all of the features had impossible outliers due to data entry errors at the highest and lowest values. In the NGRs, a common error was that often, the two letters at the beginning of the NGRs were transcribed as numbers. In addition, a number of transcriptions had data missing, or were completely blank – this was found to be due to a glitch on the MicroPasts website which caused the transcription to automatically submit when the enter key was pressed on a single-line field. Some volunteers had also added in their own notes in square brackets about the sheet they were transcribing, which was not in the instructions. These also needed to be removed as they were not part of the original dataset. Overall, however, the vast majority of data appears to have been entered correctly. 

### Representativeness of data collected

Flaws in the cropping and filling processes to produce the silhouettes entailed that of the 1198 `r #length(outlines_uncorrected)` outlines imported into Momocs, only 1137`r #length(outlines)` could be used in the final analysis. The 61 outlines which were dropped were unrecognizable from their original drawings. The 1137`r #length(outlines)` usable outlines have had some slight data loss, for example their edges have become slightly more jagged, however not enough to truly affect the overall shape. For the record sheets, however, as much data will be retained as possible, as all 1825 sheets were transcribed. This will help to account for the axe drawings which cannot be included in the morphometric analysis with Momocs, as some educated guesses can be made about their shapes based upon analysis of their measurements and comparison with other similar axes which had usable silhouettes.

\newpage

## Exploratory morphometric analysis with record sheet data

### Sorting variables

The data cleaning step after downloading the data from MicroPasts revealed that many axes did not have measurements for all 56 features. The dotplot shows a significant decrease in frequency of measurements for features below bladang (Figure \@ref(fig:features-dotplot)). 

```{r features-dotplot, echo=FALSE, messsage=FALSE, fig.cap="Dotplot to visualise the amount of measurements for each feature and the conditions of the axes."}
neo_axes_long %>%
  group_by(feature) %>%
  mutate(n = n()) %>%
  # filter(n > 50) %>%
  ungroup() %>%
  mutate(feature = fct_reorder(feature, n, .desc = FALSE),
         id = fct_reorder(as.character(axe_id), n)) %>%
  ggplot(aes(colour = condition)) +
  geom_point(aes(x = id, y = feature), size=0.5) +
  theme(axis.text.x = element_blank())
        # axis.text.x = element_text(angle = 90, vjust = 0.5),
        #legend.position = c(.8, .4)) +

```

The data cleaning step after downloading the data from MicroPasts revealed that many axes did not have measurements for all 56 features. The dotplot shows a significant decrease in frequency of measurements for features below bladang (Figure \@ref(fig:features-dotplot)). Looking at the `features_n` dataframe, bladang is recorded 1202 times, whereas the next feature below it, maxleng, is recorded just 408 times. Using 1202 occurrences as the cut-off left 19 features, which helped to reduce dimensions considerably even before PCA. Next, the conditions of the axes were considered. By far, the vast majority of axes were in complete condition.  After these exclusions, 125 axes were omitted, leaving 1700 axes in the analysis.

### Univariate

At first glance, it is evident that many of the variables’ densities show a fair amount of variation either side of the mean/median, they are mostly skewed, and mostly unimodal (Figure \@ref(fig:density-plots)). Because some of these distributions are skewed due to outliers, I have provided red and blue lines for the mean and median, respectively, for each variable. Distance between the mean and median lines grows depending on the leptokursis of the variable. This is evident in blaleng, gripoled, lefedwid, lengmaxt, lengmaxw, maxleng, polthick and weight. The two grinding measurements and potentially blathick are bimodal, whilst bladang and lonpoled appear to be trimodal. Bladang appears to have three modes very close together at more acute angles, with a rise in its tail at reflex angles. The mean and median are unhelpful measures of central tendency for these multimodal distributions, and instead we must look at the peaks (Shennan 1997, p39). Another noticeable outcome is that the cortex measurements appear to mostly be 0, with very little variation around the central values. Weight has the most skewed distribution of all, with values reaching more than 2000g, and the rug beneath the density showing that most of the weights fall below 1000g. Polwid appears the closest to a normal distribution.

```{r density-plots, message=FALSE, echo=FALSE, fig.cap="Density plots. Red line: mean; blue line: median."}
msrmnt_means <- neo_axes_long_mcf %>%
  group_by(feature) %>%
  summarise(mean.mm = mean(measurement, na.rm = TRUE))

msrmnt_meds <- neo_axes_long_mcf %>%
  group_by(feature) %>%
  summarise(med.mm = median(measurement, na.rm = TRUE))

neo_axes_long_mcf %>%
  ggplot(aes(x = measurement)) +
  geom_density(lwd = 0.5, alpha = 0.3, fill="skyblue1", color = "skyblue1") +
  geom_vline(data = msrmnt_means,
             mapping = aes(xintercept = mean.mm,
                           color = "mean")) +
  geom_vline(data = msrmnt_meds,
             mapping = aes(xintercept = med.mm,
                           color = "median")) +
  geom_rug(alpha = 0.5) +
  facet_wrap(~ feature, scales = "free", strip.position="bottom") +
  my_theme +
  theme(legend.position = "right",
        axis.text.y= element_blank(),
        axis.ticks.y = element_blank(),
        # axis.text.x = element_text(size = 6),
        axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  expand_limits(x = 0, y = 0) +
  scale_color_manual(name = "statistics",
                     values = c(median = "blue", mean = "red"))
```
The boxplots show that all features have at least some outlier measurements (Figure \@ref(fig:boxplots)). As many of the distributions are skewed, their interquartile ranges (IQRs) appear misleadingly tiny. For example, poledwid, whose IQR is a thin line just above 0, has outliers up to around 80mm. Poleng is similarly truncated. However, corbaby and corbapl do appear to be mostly 0 as their outliers are not as extreme, so do not skew the axis. The median is again misleading for multimodal distributions, plus the IQR tends to spread around the most numerous mode and obscure others. As expected, the variation in bladang appears to fall just before 100, which is where the three peaks fell in the density plot, however there are outliers at lower and higher values. We can also see that the most common values for weight are actually lower than 500, and that there are many outliers. Atypically low measurements are present in blawid and bladang. Gripoled shows the most variation in most common values. 

```{r boxplots, echo=FALSE, message=FALSE, fig.cap="Boxplots"}
neo_axes_long_mcf %>%
  ggplot(aes(x = feature, y = measurement)) +
  # geom_boxplot(lwd = 0.25, outlier.size=0.25) +
  geom_violin(alpha = 0.3, fill="skyblue1", color = "skyblue1") +
  geom_boxplot(width=0.2, lwd = 0.25, outlier.size=0.25) +
  # geom_histogram(binwidth = 1, origin = 0) +
  facet_wrap(~ feature, scales = "free", strip.position="bottom") +
  my_theme +
  theme(legend.position = "none", strip.text = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())
```

The summary statistics further indicate skewed variables, such as poledwid, whose typical values fall between 0 and 3mm, whilst the maximum value is 85. Lefedwid is also similar with most values falling between 1 and 6mm, and a maximum value of 185. As expected, the variable with the largest range is weight, with an interquartile range of 300, its lowest value being 20g, with its maximum at 2165g.   In addition, a typical blade angle lies between 80 and 90 degrees, and the largest is 180. The 1st and 3rd quartiles for the cortex measurements are both 0. After these univariate results, I decided to omit the cortex measurements as they were mostly 0 and only refer to the area of unpolished surface on the axe.

```{r summary-stats, message=FALSE, echo=FALSE, include=FALSE}
neo_axes_long_mcf2 <- neo_axes_long_mcf %>% 
  filter(!(feature %in% c("corfroby", "corbapl", "corfropl", "corbaby")))

neo_axes_wide <- neo_axes_long_mcf2 %>%
  pivot_wider(id = "axe_id", 
              names_from = "feature",
              values_from = "measurement") %>%
  column_to_rownames(var = "axe_id")

# library(skimr)
# skim_without_charts(neo_axes_wide)

summary(neo_axes_wide)

# kable(summary(neo_axes_wide), booktabs = TRUE,
#     caption = "Summary statistics") %>%
# kable_styling(latex_options = "basic", font_size = 5)
```

### K-means cluster analysis

The WSS plot displayed an ‘elbow’ or sudden change at 2 and 3, whilst the average silhouette clearly indicated 2 was the optimal number of clusters (Figure \@ref(fig:wss-silhouette)). In light of these results, k-means analyses were performed with clusters set to 2 and 3 (Figure \@ref(fig:k-means)). 

```{r wss-silhouette, echo=FALSE, message=FALSE, fig.height=3, fig.cap="WSS and average silhouette plots"}
scaled_neo_axes <- neo_axes_wide %>%
  drop_na() %>%
  scale()

p1 <- fviz_nbclust(scaled_neo_axes, kmeans, method = "wss") +
  my_theme
p2 <- fviz_nbclust(scaled_neo_axes, kmeans, method = "silhouette") +
  my_theme

p1 + p2
```
Judging by the measurements of some axes on either side of the 2-cluster k-means plot, heavier, thicker, longer axes were on the far right, and lighter, thinner and shorter ones were on the far left. For example, 60119, 60115 and 60128 all have maxlengs between 8 and 11mm and weigh 105, 135 and 140g respectively, whereas 60001, 60110 and 70002 have maxlengs of 299, 315, and 226, and weigh 1860, 1910 and 1565g. Interestingly, 60001 and 60110 have the longest maxlengs in the dataset, whilst 60119 and 60115 have the shortest,with 60128 having the 5th shortest. The clusters are partitioned through the part of the plot where most of the axes fall, almost appearing to overlap, which suggests poor partitioning or overfitting (Rhys 2019, p403).

Moving onto the 3 cluster plot, the axes on the extremeties of the plot are still in the same places, however many of the axes which fell towards the centre of the plot in either cluster have now been relocated into cluster 2. Most of the axes tend to fall into either cluster 2 or very near the edge of cluster 3. Here we can see better separation between the cluster with the longer/larger axes in and the other clusters, however there is overlap between clusters 1 and 2, which also are similar sizes, containing 166 and 143 points respectively. 

```{r k-means, echo=FALSE, message=FALSE, fig.height=10, fig.width=6, fig.cap="K-means clusters"}
kclust2 <- kmeans(scaled_neo_axes, centers = 2, nstart = 50, algorithm = "Hartigan-Wong")
kclust3 <- kmeans(scaled_neo_axes, centers = 3, nstart = 50, algorithm = "Hartigan-Wong")
kclust5 <- kmeans(scaled_neo_axes, centers = 5, nstart = 50, algorithm = "Hartigan-Wong")
kclust6 <- kmeans(scaled_neo_axes, centers = 6, nstart = 50, algorithm = "Hartigan-Wong")

kclust3_lookup <- kclust3$cluster %>%
  enframe() %>%
  rename(axe_id = name, cluster = value) %>%
  mutate_at("cluster", ~ as_factor(as.character(.)))

kclust2_lookup <- kclust2$cluster %>%
  enframe() %>%
  rename(axe_id = name, cluster = value) %>%
  mutate_at("cluster", ~ as_factor(as.character(.)))

k2 <- fviz_cluster(kclust2, data = scaled_neo_axes, labelsize=6) +
  my_theme
k3 <- fviz_cluster(kclust3, data = scaled_neo_axes, labelsize=6) +
  my_theme
k5 <- fviz_cluster(kclust5, data = scaled_neo_axes, labelsize=6) +
  my_theme

k2 /
k3 /
k5
```
The 4-cluster plot appears to have kept the majority of the longer axes that were in cluster 1 in the same cluster, however some of the bordering axes moved into cluster 4. There is still overlap between two of the clusters, 3 and 4, where the majority of the axes fall, however some of what appears to be the shortest axes have been partitioned into a separate group which contains the least axes. Clusters 3 and 4 are similar sizes.

Finally, the 6-cluster solution interestingly shows that clusters 2 and 6 have mostly the same membership as clusters 1 and 3 in the 4-cluster plot with little if any change. There are now four overlapping clusters in the centre of the plot, which contain the majority of the axes in the dataset. These overlap so considerably that it is difficult to see their borders. As the 4-cluster k-means was able to separate the two groups on the left and right of the plot which are retained when more clusters are introduced, it was decided that 4 clusters was the best choice from these options.

\newpage

### Within-cluster densities

It is clear that cluster 3 mostly contains the axes with the smallest values for blaleng, blathick, blawid, lengmaxt, maxleng, and polwid (Figure \@ref(fig:cluster-densities)). 

```{r cluster-densities, fig.width=6, fig.cap="Cluster densities"}
neo_axes_long_mcf2 %>%
  right_join(kclust3_lookup, by = "axe_id") %>%
  ggplot(aes(x = measurement)) +
  geom_density(aes(colour = cluster, fill = cluster), alpha = 0.3) +
  # geom_density(alpha = 0.2) +
  # geom_rug(alpha = 0.5) +
  facet_wrap(~ feature, scales = "free") +
  my_theme +
  theme(legend.position = "right",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.x = element_text(size=6))
```

It is clear that cluster 1 is dominated by axes with the smallest values for blaleng, blathick, blawid, lengmaxt, maxleng, and polwid, however has outliers for all of these. Cluster 1 also has a bimodal distribution for grinside, longside, gripoled, lonpoled, maxthick, weight and slightly for maxwid, and its subsidiary modes in grinside and longside are where cluster 4’s modes are. Cluster 2 appears to mostly contain the lightest axes with the smallest maxthick and longside measurements, and more of the lower values for grinside. It also has bimodal distributions for grinside, gripoled and lefedwid. Cluster 4’s distribution overlaps with cluster 2’s on a number of the variables, however generally tends to peak at slightly higher numbers than cluster 2. Finally, cluster 1 generally appears to have the highest values within it for most variables, however its distribution is not always dominated by these, for example for lengmaxw and weight where it has a wide spread. In addition, whilst cluster 4 contains axes with the highest values for weight, its peak is at lower values than cluster 3’s. Cluster 1 axes tend to have larger measurements for maxwid, maxleng, longside, maxthick, grinside, lengmaxt and lengmaxw more than the other clusters. Clusters 1, 2 and 3 appear to be widely spread for blaleng, blathick, blawid, lengmaxt, and polwid. Interestingly, all clusters show multiple modes for grinside and gripoled. Poleng, poledwid and bladang measurements have similar distributions in all clusters.

### Principal components analysis

The first PC explains the most variance, however this is still just 38.2% of the overall variance; the second PC accounts for 14.8%, and the rest of the variance is split over many subsequent PCs (Figure \@ref(fig:screeplots)). The first two PCs account for 53% of the variance. PC3 and PC4 account for 8.9 and 7.2% respectively, in total 16.1%, so these were also kept for analysis. The first 4 PCs account for 69.1% of the variance. 

```{r screeplots, fig.size=3, fig.cap = "Screeplots of eigenvalues and percentage variance explained."}

neo_axes_PCA <- drop_na(neo_axes_wide) %>%
  prcomp(center = TRUE, scale = TRUE)

sc1 <- fviz_screeplot(neo_axes_PCA, addlabels = TRUE, choice = "eigenvalue") +
  my_theme
sc2 <- fviz_screeplot(neo_axes_PCA, addlabels = TRUE, choice = "variance") +
  my_theme

sc1 + sc2

```

Looking at the variable loadings, are 9 variables which are strongly negatively correlated with PC1, with maxwid and weight being the strongest at -0.85 and -0.84 respectively (Table \@ref(tab:variable-loadings)). Maxthick, maxleng, blawid, blathick, blaleng, lengmaxt and longside are the other 7 correlated variables. For PC2, polthick, polwid, poledwid and lonpoled are strongly positively correlated, and longside and grinside are strongly negatively correlated. Finally, for PC3, bladang, gripoled, lefedwid have strong positive correlations and lengmaxt is strongly negative, and PC4’s strongest correlation is positive with poleng, followed by negatives with blathick and blaleng.

```{r variable-loadings}

library(magrittr)

map_dfc(1:4, ~neo_axes_PCA$rotation[, .] * abs(neo_axes_PCA$sdev)[.]) %>%
  mutate(across(everything(), round, digits = 2)) %>%
  set_rownames(rownames(neo_axes_PCA$rotation)) %>%
  set_colnames(c("PC1", "PC2", "PC3", "PC4")) %>%
  arrange(desc(abs(PC1))) %>%
  kable(row.names=TRUE, 
      caption = "Variable loadings sorted in order of largest magnitude correlation with PC1.", booktabs = TRUE) %>%
  kable_styling(font_size = 10)
```

The variable biplot for PC1 and PC2 shows that most of the variables corrleate with one another, with the exception of polwid, polthick, poleng, bladang, and lonpoled, which correlate with one another but less so with the rest. Polthick correlates the least with any variables. Longside, grinside and lefedwid are almost perfectly correlated, as are blawid and blaleng (Figure \@ref(fig:pc1-pc2)). The biplot of the individuals for PC1 and PC2 shows long, heavy, thick axes with thick blades on the far left side, and the shortest, lightest, thinnest axes with the thinnest blades on the far right. In the centre of the plot we see the majority of the axes, however there are some outliers toward the top of the plot which score highly on the poll measurements represented by PC2, such as 10040 and 81004. Some axes toward the centre score highly on only some of the negatively correlated variables in PC1. For example, 60072 is fairly long with a maxleng of 113mm, but weighs just 160g. Meanwhile, 60117 weighs 955g but is only 21.3mm long, and is positioned at the bottom of the plot since it has small polthick and polwid measurements.

```{r pc1-pc2, fig.height=10, fig.cap = "PCA: individuals and variables for PC1 and PC2"}

# https://www.benjaminbell.co.uk/2018/02/principal-components-analysis-pca-in-r.html
# https://cmdlinetips.com/2019/04/introduction-to-pca-with-r-using-prcomp/

# library(broom)
# 
# # https://broom.tidymodels.org/reference/tidy.prcomp.html
# au <- augment(neo_axes_PCA, data = drop_na(neo_axes_wide))
# 
# ggplot(au, aes(.fittedPC1, .fittedPC2)) +
#   geom_text(aes(label = .rownames)) +
#   coord_fixed()

# neo_axes_pca_tidy <- tidy(neo_axes_PCA, matrix = "u") %>%
#   filter(PC < 3) %>%
#   pivot_wider(names_from = PC,
#               names_prefix = "PC")

biplot(neo_axes_PCA, pc.biplot = TRUE)

# fviz_pca_biplot(neo_axes_PCA) +
#   coord_fixed()

# neo_axes_pca_tidy %>%
#   ggplot() +
#   geom_point(aes(x = PC1, y = PC2))

# autoplot(neo_axes_PCA, x = 1, y = 2,
#          variance_percentage = TRUE, label = FALSE) +
#   coord_fixed()


# pc2 <- autoplot(neo_axes_PCA, x = 1, y = 2, variance_percentage = TRUE, colour = 'grey', loadings.label = TRUE, loadings.colour = 'blue', loadings.label.colour = 'blue', loadings.label.repel = TRUE) + my_theme
# 
# pc1 /
# pc2

```

For PC3 and PC4, the variable biplot shows bladang and lefedwid, the positively correlated variables with PC3, correlating with one another (Figure \@ref(fig:pc3-pc4)). The individuals biplot shows that there are a few axes which score highly on these extending to the right of the plot, however the vast majority fall around the centre. We can also see lengmaxt and maxleng correlating with one another, which are negatively correlated with PC3, and some long axes extending to the left of the plot. Finally we can see poleng, strongly positively correlated with PC4, extending vertically to the top of the plot, however there is just one outlier scoring highly on this variable. Examining PCs other than 1 and 2 can reveal outliers which were not visible on the first two PCs, such as 81004 which has the largest poleng measurement at 52mm, and 60126 which has a bladang of 180 degrees. As the variable loadings are not as strong for these PCs, in addition to how little variance they explain, it is difficult to discern the relations between axes on either side of PCs 3 and 4 (Shennan 1980, p267).

```{r pc3-pc4, fig.height = 10, fig.cap = "PCA: individuals and variables for PC2 and PC3"}

pc3 <- autoplot(neo_axes_PCA, x = 3, y = 4, variance_percentage = TRUE, 
                label = FALSE) + my_theme
pc4 <- autoplot(neo_axes_PCA, x = 3, y = 4, variance_percentage = TRUE, 
                colour = 'grey', loadings.label = TRUE, loadings.label.repel=TRUE,
                loadings.colour = 'blue',loadings.label.colour = 'blue') + my_theme

pc3 /
pc4

```

### Clusters on PCA

blbalballa

```{r pca-cluster, fig.cap = "Clusters colour-coded onto plots of the two pairs of axes"}
pcl1 <- autoplot(neo_axes_PCA, data = kclust3, x = 1, y = 2, variance_percentage = TRUE, colour = 'cluster') + my_theme
pcl2 <- autoplot(neo_axes_PCA, data = kclust3, x = 3, y = 4, variance_percentage = TRUE, colour = 'cluster') + my_theme

pcl1 /
pcl2
```

\newpage

## Outline morphometric analysis with Momocs

### Data cleaning

Before perfoming any analyses on the shapes, I first needed to check whether all of the outlines were successful. This was done by using the Momocs function `panel` and displaying the names as just the ID numbers from each filename over each shape, which I selected from the character vector of filenames using a regular expression (Figure \@ref(fig:image-sorting)). Otherwise the filenames were too long and illegible, overlapping on top of the shapes. I then identified all of the erroneous shapes and removed them from the list of filenames to import into Momocs. 1137`r #length(outlines)` were acceptable to use, as some of the outlines were completely unrecognizable from their original drawings. 

```{r image-sorting, results='hide', warning=FALSE, message=FALSE, fig.cap="All outlines imported into Momocs before inspection"}

outlines_uncorrected <- read_rds("data/outlines.Rds")

panel(outlines_uncorrected)
```

The final dataset is below (Figure \@ref(fig:outline-corrections)). After cleansing the dataset of any erroneous outlines, I then used `efourier` with its default normalize setting. All axes were aligned the same way before importing into Momocs, with their blades at the bottom and their polls at the top.

```{r outline-corrections, results='hide', message=FALSE, warning=FALSE, fig.cap="Final outlines for analysis after incorrect shapes removed"}

outline_errors <- read_csv("data/error-fills.csv") %>% pull()

errors <-
  tibble(stem = names(outlines_uncorrected)) %>%
  mutate(axe_id = str_extract(stem, "[0-9]{2,}[ab]*")) %>%
  filter(axe_id %in% outline_errors) %>%
  pull(stem)

outlines <- Out(
  outlines_uncorrected[which(!names(outlines_uncorrected) %in% errors)])

panel(outlines)
```

Next was to determine how many harmonics should be used when performing elliptical fourier analysis on the outlines. To do this I used two methods: firstly plotting `harm_pow` of individual axes, and secondly `hcontrib` on the overall dataset, showing how many harmonics it would take to adequately reconstruct the mean axe shape. The former function shows a line plot of how much of the shape has been reconstructed by each harmonic, and also shows at which point this stops improving, which is where the line plateaus. I did this for the first, middle and last axes in the data-set, all of which appeared to show the 12th harmonic as the point at which the shape stops improving noticeably (Figure \@ref(fig:harmonic-power)).

```{r harmonic-power, results='hide', message=FALSE, warning=FALSE, fig.cap="Plotting harmonic power of first and middle axe outlines in the dataset."}
#checking harmonic power, how many to use in ef
ef_first <- efourier(outlines[1], 12, norm=FALSE)

ef_mid <- efourier(outlines[599], 20, norm=FALSE)

plot(cumsum(harm_pow(ef_mid)[-1]), type='o',
     main='Cumulated harmonic power without the first harmonic',
     ylab='Cumulated harmonic power', xlab='Harmonic rank')
```

This was also the case when running the `hcontrib` function on the entire dataset passed to efourier with 20 harmonics (Figure \@ref(fig:hcontrib)). As a result of these checks, 12 harmonics was settled on for the elliptical fourier transformation.

```{r hcontrib, results='hide', message=FALSE, warning=FALSE, fig.cap="Harmonic contribution plot to show how many harmonics can reconstruct a typical axe outline."}
#elliptical fourier transform
ef <- efourier(outlines, 20)

hcontrib(ef, harm.r = 1:20, col="lavender")
```

Before running PCA on the efourier-transformed outlines, `Pccontrib` was used to determine the variation in the outlines accounted for by each PC up to 10 (Figure \@ref(fig:pccontrib)). Here, we can see that the first PC accounts for width, and PC2 accounts for how wide the blade is compared to the rest of the axe. PC3 appears to distinguish rounder blades and edges from more straight blades and edges, but seems to contain shapes which do not exist. The rest of the PCs do not appear to show much variation at all.

```{r pccontrib, results='hide', message=FALSE, warning=FALSE, fig.cap="Variation in outlines explained by each principal component."}
pca <- PCA(ef)
PCcontrib(pca, nax=1:10)
```

When plotting the Momocs PCA output, example mean shapes are drawn at intervals across the morphospace. The plot of of PCs 1 and 2 showed wider, rounder axes toward the left of the first component, and thinner, more rectangular axes toward the right, with the majority of axes falling around and just beyond the origin (Figure \@ref(fig:momocs-pca)). 

```{r momocs-pca, results='hide', message=FALSE, warning=FALSE, fig.cap="PCA of elliptical Fourier-transformed outlines"}

plot(pca)
```

The mean shapes on the morphospace show some odd, seemingly predictive shapes at the far edges where no axes are plotted, for example the almost bottle-like shapes at the top and bottom right corners. From the PCA plot, it would be fair to say that there are perhaps 3 or 4 clusters for k-means, as there are the extreme cases of very thin straight axes and much fatter, square or round axes, with a large group of the typical mean shape of axes, which is slightly trapeziodal, and in between the widths of these two groups. We can see that the mean axe shape becomes more trapezoidal further up PC2, and more straight toward the middle, and then thinner on the opposite side of the shape as we reach the bottom. This appears to be why there are almost bottle-shaped outlines in the top right and bottom right corners of the plot with the narrow part of the shape on opposite ends. At first glance it would appear that the shapes are facing two different directions, which was initially assumed to be due to incorrect alignment, however this has been observed in other studies which use Momocs (Bourcy 2013, p49, Figure 13).  From this it can be said that there are no axe shapes which have a wider poll end than blade, so this is why there are no axes plotted at the bottom, and likewise none have such a thin poll compared to the blade as the top right shape. As PC1 and PC2 together account for 90.7% of the variation, and PC3 appeared to contain noisy, non-existent shapes, only the first two components were compared.

The k-means function in Momocs very helpfully plots the clusters onto the PCA results, drawing the mean axe shape of each cluster onto the morphospace. K-means clustering was performed with 3, 4 and 6 clusters, for comparison with the measurement analysis, and also due to the results of the PCA on the efourier-transformed shapes. Firstly, the 3-cluster possible solution shows thick axes to the left, thin axes to the right, and axes which are between the two extremes in the centre cluster (Figure \@ref(fig:momocs-3kmeans)).

```{r momocs-3kmeans, results='hide', fig.cap="Momocs k-means with 3 clusters"}

kmeans2 <- KMEANS(pca, centers = 2,
                 algorithm = "Hartigan-Wong")
```

For 4 clusters, the plot shows two very similar looking mean axe shapes for the two central clusters, however the thinnest group and the widest group now have more exaggerated mean shapes and smaller cluster membership. This appears to be an improvement on the 3-cluster solution as the mean shapes of the clusters on either end of PC1 appeared more diluted prevously (Figure \@ref(fig:momocs-4kmeans)). 

```{r momocs-4kmeans, fig.cap="Momocs k-means with 4 clusters"}
kmeans3 <- KMEANS(pca, centers = 3,
                 algorithm = "Hartigan-Wong")
```

When attempting to separate the axe shapes into 6 clusters, the plot shows that there is not much change in the thinnest group on the far right, however the widest axes have now been split into two wide groups that appear to have very similar mean shapes, and the axes which fall around the origin have been split into three clusters, also with similar mean shapes (Figure \@ref(fig:momocs-6kmeans)). The 6-cluster solution does not reveal much more about the potential groups of axe shapes that may exist in this dataset compared to 4 clusters, as similar shapes are forced into separate groups arbitrarily here. What the 6-cluster plot does suggest, however, is that the two groups of widest and thinnest shapes in the 4-cluster plot are sensible, as there is little relocation from these.

```{r momocs-6kmeans, fig.cap="Momocs k-means with 6 clusters"}
kmeans5 <- KMEANS(pca, centers = 5,
                 algorithm = "Hartigan-Wong")
```


In order to see the cluster membership in the 4-cluster solution more clearly, Momocs’ `panel` function was used with colours set to display the clusters, and the axe_ids as the names (Figure \@ref(fig:panel-clusters)). Here we can see that the 4 clusters have been partitioned in a way that makes sense: all of the axes in the thickest group are in fact the thickest, and those in the thin group are the thinnest of all. The two similar clusters which were in the centre of the k-means plot do appear slightly different here, with the axes in the blue group being consistently slightly less wide than those in the green. Despite PC2 accounting for how trapezoidal or straight the axe shapes were, this does not appear to have been a deciding factor in the k-means clustering. There are both straighter and more trapezoidal axes in most of the groups, apart from the thinnest group, which by chance is also the straightest. 

```{r panel-clusters, fig.cap='The 4 Momocs clusters colour coded onto a panel plot of axe outlines'}
outline_names <- names(outlines) %>% str_extract("[0-9]{2,}[ab]*")

panel(outlines, palette=col_spring, 
      fac=as.factor(kmeans3$cluster), names=as.factor(outline_names), 
      cex.names=0.5, fromtop=TRUE) # dim = c(47, 25))
```

Here we can see that the 4 clusters have been partitioned in a way that makes sense: all of the axes in the thickest group are in fact the thickest, and those in the thin group are the thinnest of all. The two similar clusters which were in the centre of the k-means plot do appear slightly different here, with the axes in the blue group being consistently slightly less wide than those in the green. Despite PC2 accounting for how trapezoidal or straight the axe shapes were, this does not appear to have been a deciding factor in the k-means clustering. There are both straighter and more trapezoidal axes in most of the groups, apart from the thinnest group, which by chance is also the straightest. Finally, to get a feel for the appearance of a typical axe in each cluster, mean shapes were plotted (Figure \@ref(fig:meanshapes)).

```{r meanshapes, fig.height=4, fig.cap="Mean shapes for each of the 4 clusters"}

axe_means <- MSHAPES(ef, fac = as.factor(kmeans2$cluster))
Out(axe_means$shp) %>% panel(names=TRUE)
```

