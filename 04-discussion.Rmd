# Discussion {#discussion}

## Limitations and success of the data collection methods

Because this project works with old technical drawings which were never intended to be read by computer software, there was always going to be a degree of difficulty when processing them into the desired format. Faint pencil lines, labels close to outlines and lack of space between views or bounding box borders created most of the problems in the cropping and filling processes. One of the most common issues was that nearby writing would become joined to the largest contour and filled as one shape with the rest of the view. As the filling method removes any contours which are smaller than the largest, if these are connected to the largest they become amalgamated into one shape.  Most notably, some of the axes which either overlapped or were drawn very close to one another also happened to be among the largest, which is due to the fact that Pitts was drawing to scale. This unfortunately meant that the final outline dataset was biased against the largest axes, which later became apparent when comparing the analysis results.

Although some of the original drawings are just unusable with this method due to overlapping, there are ways in which it could be improved to successfully crop and fill more of the drawings. One way to improve the method would be to increase the size of the bounding boxes used to find the coordinates for cropping the views. This could be done by further dilating the binary thresholds of the drawings that are used to find the contours, which would increase the size of the contours, and thus space within the bounding boxes. After this step it would then be acceptable to increase the contrast despite noise coming through from the page behind, as increasing the space around the view would make it the largest continuous contour in the image, so these would be ignored and removed. Another possible improvement to this dataset would be to manually inspect the cropped drawings with more or less than three views associated as some may have filled correctly.

As MicroPasts uses Pybossa, which has a page limit to prevent their server from being overloaded with requests, the option to export task runs on the MicroPasts web interface limits export to the first 20 completed tasks. Additionally it appears as though Pybossa has not been maintained, and some of its documentation is no longer available. As a result there were no instructions on how to bypass the page limit and download data from a project, which necessitated writing a reasonably complicated R script and `Makefile` to overcome. In addition, a potential pitfall of the MicroPasts website is that because it is specific to archaeology and heritage, it most likely does not get as much traffic as other multidisciplinary crowdsourcing platforms such as Zooniverse, which has incidentally been around for longer. This could have contributed to the relatively slow uptake of tasks. Conversely, because of the subject-specific nature of the platform, the volunteers may have particular interest in and enthusiasm for contributing helpfully to a project. In this project’s case, it does seem as though volunteers took special care in data entry, as outlined below.

Once the data was downloaded and inspected, there were a number of common mistakes which repeatedly arose in the transcribed data. One example was that because the position of lefedwid moved depending on the sheet format, it would usually have swapped measurements with bladang, as this was the field next to it.  Fortunately, many data entry errors were reasonably easy to detect, as they usually came in the form of extremely high or low outliers. Some aspects of the sheets were ambiguous, such as numbers which were clearly written, but crossed out in a line. There were also numbers written outside of fields on the record sheets. Because of unclear meanings, some volunteers included messages in square brackets in the ‘Comments’ field indicating that the number was crossed out. This suggests that perhaps an ‘Any other comments’ field, not to be used in the final data but to help with data cleaning, would have been useful here. Additionally, a number of volunteers had entered values in the wrong fields due to the sheet fields in the image changing from the order of the fields in the form. However, some of these also appeared to have been because there would be an empty field in the record sheet after a series of consecutively completed fields, and the transcriber would enter the previous field's value in the one which should be empty. This could potentially have been mitigated against by changing the layout of the forms to imitate that of the record sheets, however the format would still change from sheet-to-sheet. Numbers instead of letters transcribed at the beginning of the UK NGRs could have been a result of the decline in use of NGRs compared to lat-longs in recent years, so perhaps this should have been explained in the instructions. This would also have been alleviated if data validation was employed in the NGR field so that anything other than A-Z could not be entered as the first two characters. In addition, the glitch which caused the transcription to be submitted when the enter key was pressed on a single-line field is present in other MicroPasts projects, as the template for this project was taken from its GitHub and has been used by others. The glitch did, however, result in surprisingly few completely blank submissions. On balance, volunteers for this project appeared to take care with data entry, and the mistakes made were usually due to ambiguous handwriting. 

Some axes still appeared to have confusingly low or high values for some measurements even in the original data, especially when taken in context with some of the maximum measurements such as maxleng or maxwid. For example, in the original record sheet, axe 60117 had a longside of 190mm, but a maxleng of 21.3mm. Not only does it not make sense that the length of the left side edge would be larger than the maximum length, but an axe with a maximum length of just over 2cm cannot be possible. When inspecting the cleaned MicroPasts data it was clear that 22 other axes had measurements for maxleng which were far too small. These were present in the original data, and it appears as though Mike Pitts had been using centimetres and and millimetres interchangeably. In addition, many of these axes had measurements with decimal points which looked as though they had been slightly scribbled out, however still looked like a decimal point, so the transcriber had still included them. These measurements were multiplied by 10 to give the value in milimetres. Another ambiguity was that some sheets had ‘NFR’ written above ‘Condition’, rather than underneath, and the meaning of this was unclear, so it was left out.

## Results from morphometric analyses

### Measurements from the record sheets

That there were 56 features on each record sheet, but most axes only had 19 of these recorded, and most of these axes were complete, suggests potential data collection bias. This is further suggested by the fact that the first few axes with the earliest collection dates, from 10001 to 10033, had large record sheets and were completely filled, but sheets recorded after those were not. Perhaps these record sheets were created before Pitts knew the sample size, with the shorter versions created after. Nonetheless, even these shorter versions were not consistently completed. Although it is most likely not possible that these features did not exist on the axes, this considerable reduction of variables did simplify the analysis. Of the 56 record sheet variables, there were just 13 which were recorded for over 1200 axes. These 13 variables did not include blawid or polwid, which were useful measurements for defining shape, and were reduced to 9 when the redundant cortex variables were removed. The only poll variables which made the cut were poledwid and lonpoled, which refer to very specific, tiny parts of the poll, and not the overall size of that end of an axe. It is interesting and perhaps peculiar that useful measurements to discern size, such as maxleng, were measured for a surprisingly small amount of axes, and that small measurements such as poledwid were the most frequent.
According to Pitts, every complete axe in each collection he visited had their measurements taken (Pitts 1996, p328). Cast represents replica axes which were created from casts taken of the originals, so here weight cannot be recorded as the material the casts were made from will be different to the original axe. Reflaked and reworked are taken to mean that an axe had been repurposed later in its life cycle, and the shape had been changed, so the design may not be the same as when it was first manufactured. The distinction between reflaked and reworked is that reflaked is specific to flint implements. There were also fragments, which are either broken or incomplete axes. Finally, roughout axes are those which have complete shapes, but are not polished. It was based on this information that the decision was made to only keep complete and roughout axes, since these would retain the shape. Interestingly, out of Pitts’ larger sample of 1919 axes – 124 of these were excluded from this investigation due to problems matching up axe IDs – only 1638 were used in his analysis. This is said to be because those with unique shapes and those which were unground were removed (p330). 

The most interesting distributions shown in the univariate analyses were the bimodal grinding variables, as the two groups arising here may indicate differing manufacuring practices. The three modes in bladang are not really significant as these are all acute angles, and the real difference is between these and the 180 degree angles, which are comparatively rare. Both the 9 and 19 variable PCAs had similar PC1 correlations with variables that defined overall size of axes such as weight and maxthick, and also with grinside. Interestingly though, PC2 on the 19-variable dataset showed considerable correlation with all of the poll features compared to its PC1, whereas the 9-variable data PC2 only strongly correlated with poledwid. From the results of the 19-variable PCA, it could be possible to predict the shape of an axe based upon where it is positioned on PC1 and PC2. Because the blade is not usually smaller than the poll, the width of the poll can suggest how square an axe is, as very large polls will most likely be a similar size to the blade. Axes plotted at the bottom of PC2 are most likely to be straight rather than trapezoidal, since they have large poll measurements. Those which are further to the left of PC1 but far down PC2 are likely to be more square since they are shorter, and likewise far down PC2 but to the right of PC1 will be more rectangular since they are longer. If an axe is plotted near the top of PC2, but to the far left of PC1, it will be more triangular, and to the far right will be tear-drop shaped, again due to the length of the axe. Of course, these are extreme cases, and most axes tend to fall around the origin. PC3 and 4 of the 19 variables are also worth mentioning as PC3 suggests that poleng and lengmaxt have an inverse relationship with blathick and bladang, whilst PC4 appears to be showing an interesting negative correlation between the amount of grinding on the poll edge and poll edge width, which could indicate how grinding changes the poll width.

Whilst both the WSS and silhouette plots suggested that 2 was the optimum number of clusters for this dataset, this was shown to be an over-simplification, as extreme cases on the far ends were lumped in with the more typical axes around the origin. As the axes on both clusters' extremeties were the same as those on the edges of PC1, the axes were clearly just arranged from largest on the right to smallest on the left, and split at some arbitrary point into two. The three-cluster solution was a slight improvement on this as some of the more typical axes were moved from cluster 1 into cluster 2, however not completely separating the very largest axes from the more typical ones. Membership of cluster 2 appears to be based on having large bladang, gripoled and lonpoled measurements, in addition to mostly having middle-of-the-road values for other variables. Because the 5-cluster solution showed little change in cluster 1, and created overlapping clusters, it helped to confirm that any more than 3 clusters would not make sense. Still, however, the 3-cluster solution left many of the typical axes intermixed with extreme cases in each cluster, particularly for cluster 1. The density plots of the variable distributions within each cluster confirm that cluster 1 has the axes which are the heaviest, thickest, longest and most ground. These also reaffirm that cluster 2 membership appears to be based on having smaller measurements for PC1-correlated variables than cluster 1, but larger than cluster 3, but also having the highest for PC2-correlated variables.

## Axe outlines

PC1 accounts for aspect ratio of the axe shapes, and PC2 explains the ratio of blade width to poll width, starting from straight oblong shapes at one end to triangular shapes on the other. Wilczek *et al.*’s study on Bronze Age axes which also uses Momocs had similar results from their first two components, with the first representing aspect ratio and the second showing the blade to body width ratio (2015 p385). On the morphospace, the majority of axes were arranged around four mean axe shapes; a narrower and a wider trapezoidal shape, and a narrower and a wider oblong shape, just to the left of and at the origin.  It is also surprising that two axes with smaller blade ends than poll ends are present, and the fact that there are so few begs the question of whether they really are complete, or perhaps whether it is an artefact of the silhouette produced from the drawing. It would be fair to say that the PCA results indicate the presence of at least three distinct shapes in the dataset: straight and narrow oblongs, trapezoidal shapes, and squat square shapes. These squat shapes could be axes which have similar poll widths to blade widths, which were spotted at the bottom of PC2 in the record sheet data PCA.

Now that the existence of some more uncommon shapes is clear, it would be fair to hope for a satisfactory k-means result to separate these into their own groups, rather than diluting them with more of the typical axe types partitioned into the same group. The latter seems to be the result for the 2-cluster k-means analysis, which sees an already-existing cluster being split into two groups along with outliers at either end. The 3-cluster solution was more satisfactory in that many of these typical axes were contained in the central cluster, with a narrower and a wider group at either end, but these still contain some of the typical axes. The best option was 4 clusters, as many of the more average axes were partitioned between the wider and narrower typical axe shapes in the centre, which appear much like the mean shapes in PCA where most of the axes fell. There were also less axes in the widest and narrowest groups of the 4-cluster arrangement which makes sense as it did not appear that there were many of these extreme cases in the PCA.

## Comparisions

The first and second principal components in the PCA analysis on the elliptical-Fourier-transformed outlines appear remarkably similar to the first two components in the PCA of the axe measurement data with 19 variables. PC2 in the 19-variable reduced dataset relates to all of the poll features, whilst Momocs PC2 relates to ratio of blade to poll width. Meanwhile, PC1 is characterised by thickness, width, weight, length, and PC1 in Momocs by width, or aspect ratio. Rather square shapes, as predicted from the 19-variable PCA of the axe measurements, are indeed present in the outlines dataset. However, the mean shapes of the outlines from both the 9-variable and 19-variable clusters of the MicroPasts data show little or no distinction from one another, whilst Momocs was clearly able to pick out differing shapes in the outline dataset. This plainly shows that Momocs was better able to separate the axes based on shape than PCA and k-means on their dimensions. This is not too surprising since the results of the k-means on the MicroPasts data showed typical axes lumped in with extreme cases in all three clusters, which most likely resulted in diluted mean shapes. Another unsurprising outcome is that measurement group 1, the largest axes, are the least present in the outlines dataset; this is most likely a result of the failed silhouettes mostly being for the largest axes. The most narrow axes tend to also be the smallest axes, whilst the other shape groups tend to be split evenly between the middle and largest size groups. Overall, shape and size do not appear to necessarily dictate one another. It is easy to see why 'numerical taxonomy' type analyses have fallen out of fashion in archaeology, as it is difficult to group artefacts based on size alone due to its nature as a sliding scale, which will always leave edge cases in similar groups to typical individuals. 

Looking at the distributions of where these axes were found across Britain, the most concentrated areas could potentially be related to ancient mine locations in south-west England, Norfolk, Wales and Cumbria (Shauer et al. 2019b 151). Four mines were located in southernmost England, with one in Norfolk, one in Cumbria and two in Wales. It is particularly interesting that there is a small concentration of the largest axes around the Cumbria area. Of course, that the find places tend to accumulate in certain areas mostly in southern England could be a consequence of Mike Pitts being able to travel to these areas more easily. Similar axes do not tend to cluster near each other geospatially, and generally speaking it appears as though all shapes and sizes are intermingled across Britain. This could further illustrate the highly interwoven trade network of stone tools during this period (Shauer et al. 2019b 20).